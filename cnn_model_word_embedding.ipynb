{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import functools\n",
    "import ast\n",
    "import keras\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D,MaxPool1D,GlobalAveragePooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.set_session(session)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = lambda x: ast.literal_eval(x)\n",
    "conv = {'Tags': generic}\n",
    "df = pd.read_csv('data/data_final.csv', converters=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(frac=0.2, random_state=2020)\n",
    "x1 = sample['Body']\n",
    "y1 = sample['Tags']\n",
    "max_words = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words,  lower = True)\n",
    "tokenizer.fit_on_texts(x1)\n",
    "sequences = tokenizer.texts_to_sequences(x1)\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "# pad sequences\n",
    "max_length=min(200,max([len(s.split()) for s in x1]))\n",
    "x = pad_sequences(sequences, maxlen=max_length, padding='post') #previously was pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit_transform(y1)\n",
    "\n",
    "# saving\n",
    "with open('binarizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(multilabel_binarizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('binarizer.pickle', 'rb') as handle:\n",
    "    multilabel_binarizer = pickle.load(handle)\n",
    "\n",
    "y = multilabel_binarizer.transform(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148964, 342)\n",
      "(148964, 200)\n",
      "502544\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(tokenizer.word_index) + 1\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "print(vocab_size)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119171, 200)\n",
      "(14896, 200)\n",
      "(14897, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['states', 'df', 'lt', 'map', 'data', 'state', 'xa', 'states', 'df', 'subset', 'states', 'df', 'group', '8', 'get', 'rid', 'of', 'dc', 'xa', 'states', 'df', 'st', 'lt', 'state', 'abb', 'match', 'states', 'df', 'region', 'tolower', 'state', 'name', 'attach', 'state', 'abbreviations', 'xa', 'xa', 'states', 'df', 'value', 'value', 'states', 'df', 'st', 'xa', 'xa', 'p', 'qplot', 'long', 'lat', 'data', 'states', 'df', 'group', 'group', 'fill', 'value', 'geom', 'polygon', 'xlab', 'ylab', 'main', 'main', 'opts', 'axis', 'text', 'y', 'theme', 'blank', 'axis', 'text', 'x', 'theme', 'blank', 'axis', 'ticks', 'theme', 'blank', 'scale', 'fill', 'continuous', 'name', 'xa', 'p2', 'p', 'geom', 'path', 'data', 'states', 'df', 'color', 'white', 'alpha', '0', '4', 'fill', 'na', 'coord', 'map', 'project', 'xa', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "\n",
    "# Creating texts \n",
    "my_texts = list(map(sequence_to_text, [x_train[51]]))\n",
    "print(my_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          50254400  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 186, 500)          750500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 342)               137142    \n",
      "=================================================================\n",
      "Total params: 51,342,442\n",
      "Trainable params: 51,342,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_length = 500\n",
    "\n",
    "output_dims = [100]\n",
    "for output_dim in output_dims:\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, output_dim, input_length=x_train.shape[1]))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filter_length, 15, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPool1D())   \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc \n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy', 'top_k_categorical_accuracy', top1_acc, top5_acc, auc]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 119171 samples, validate on 14896 samples\n",
      "Epoch 1/10\n",
      "119171/119171 [==============================] - 541s 5ms/step - loss: 0.0231 - acc: 0.9948 - top_k_categorical_accuracy: 0.5786 - top1_acc: 0.3378 - top5_acc: 0.5786 - auc: 0.8236 - val_loss: 0.0179 - val_acc: 0.9955 - val_top_k_categorical_accuracy: 0.6942 - val_top1_acc: 0.4176 - val_top5_acc: 0.6942 - val_auc: 0.8841\n",
      "Epoch 2/10\n",
      "119171/119171 [==============================] - 535s 4ms/step - loss: 0.0166 - acc: 0.9957 - top_k_categorical_accuracy: 0.7355 - top1_acc: 0.4477 - top5_acc: 0.7355 - auc: 0.9020 - val_loss: 0.0172 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7103 - val_top1_acc: 0.4174 - val_top5_acc: 0.7103 - val_auc: 0.9123\n",
      "Epoch 3/10\n",
      "119171/119171 [==============================] - 537s 5ms/step - loss: 0.0146 - acc: 0.9960 - top_k_categorical_accuracy: 0.7834 - top1_acc: 0.4813 - top5_acc: 0.7834 - auc: 0.9205 - val_loss: 0.0173 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7226 - val_top1_acc: 0.4349 - val_top5_acc: 0.7226 - val_auc: 0.9258\n",
      "Epoch 4/10\n",
      "119171/119171 [==============================] - 536s 4ms/step - loss: 0.0131 - acc: 0.9962 - top_k_categorical_accuracy: 0.8130 - top1_acc: 0.5044 - top5_acc: 0.8130 - auc: 0.9307 - val_loss: 0.0180 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7195 - val_top1_acc: 0.4284 - val_top5_acc: 0.7195 - val_auc: 0.9342\n",
      "Epoch 5/10\n",
      "119171/119171 [==============================] - 536s 4ms/step - loss: 0.0121 - acc: 0.9964 - top_k_categorical_accuracy: 0.8349 - top1_acc: 0.5169 - top5_acc: 0.8349 - auc: 0.9375 - val_loss: 0.0189 - val_acc: 0.9955 - val_top_k_categorical_accuracy: 0.7143 - val_top1_acc: 0.4282 - val_top5_acc: 0.7143 - val_auc: 0.9399\n",
      "Epoch 6/10\n",
      "119171/119171 [==============================] - 536s 4ms/step - loss: 0.0113 - acc: 0.9966 - top_k_categorical_accuracy: 0.8504 - top1_acc: 0.5276 - top5_acc: 0.8504 - auc: 0.9423 - val_loss: 0.0195 - val_acc: 0.9954 - val_top_k_categorical_accuracy: 0.7075 - val_top1_acc: 0.4219 - val_top5_acc: 0.7075 - val_auc: 0.9442\n",
      "Epoch 7/10\n",
      "119171/119171 [==============================] - 536s 4ms/step - loss: 0.0107 - acc: 0.9968 - top_k_categorical_accuracy: 0.8617 - top1_acc: 0.5339 - top5_acc: 0.8617 - auc: 0.9460 - val_loss: 0.0206 - val_acc: 0.9954 - val_top_k_categorical_accuracy: 0.7048 - val_top1_acc: 0.4215 - val_top5_acc: 0.7048 - val_auc: 0.9473\n",
      "Epoch 8/10\n",
      "119171/119171 [==============================] - 538s 5ms/step - loss: 0.0103 - acc: 0.9969 - top_k_categorical_accuracy: 0.8712 - top1_acc: 0.5393 - top5_acc: 0.8712 - auc: 0.9487 - val_loss: 0.0217 - val_acc: 0.9954 - val_top_k_categorical_accuracy: 0.7002 - val_top1_acc: 0.4170 - val_top5_acc: 0.7002 - val_auc: 0.9497\n",
      "Epoch 9/10\n",
      "119171/119171 [==============================] - 537s 5ms/step - loss: 0.0099 - acc: 0.9970 - top_k_categorical_accuracy: 0.8779 - top1_acc: 0.5463 - top5_acc: 0.8779 - auc: 0.9508 - val_loss: 0.0223 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6983 - val_top1_acc: 0.4161 - val_top5_acc: 0.6983 - val_auc: 0.9516\n",
      "Epoch 10/10\n",
      "119171/119171 [==============================] - 537s 5ms/step - loss: 0.0097 - acc: 0.9971 - top_k_categorical_accuracy: 0.8833 - top1_acc: 0.5507 - top5_acc: 0.8833 - auc: 0.9525 - val_loss: 0.0228 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6913 - val_top1_acc: 0.4141 - val_top5_acc: 0.6913 - val_auc: 0.9532\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=16,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/basic_model_word_embedding.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model/basic_model_word_embedding.h5\", \n",
    "                                custom_objects={'top1_acc':top1_acc, 'top5_acc':top5_acc, 'auc':auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14897/14897 [==============================] - 6s 428us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.022464561751333028\n",
      "Test acc: 0.9953319010554028\n",
      "Test top_k_categorical_accuracy: 0.7014835201958534\n",
      "Test top1_acc: 0.4132375646163259\n",
      "Test top5_acc: 0.7014835201958534\n",
      "Test auc: 0.8888032306854682\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(model.metrics_names)):\n",
    "    print(\"Test {}: {}\".format(model.metrics_names[i],score[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          50254400  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 186, 500)          750500    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 179, 500)          2000500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 89, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 82, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 41, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 34, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 342)               137142    \n",
      "=================================================================\n",
      "Total params: 57,343,942\n",
      "Trainable params: 57,343,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_length = 500\n",
    "output_dims = [100]\n",
    "for output_dim in output_dims:\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, output_dim, input_length=x_train.shape[1]))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filter_length, 15, padding='valid', activation='relu', strides=1))\n",
    "    model.add(Conv1D(filter_length, 8,activation='relu'))\n",
    "    model.add(MaxPool1D())\n",
    "    model.add(Conv1D(filter_length, 8,activation='relu'))\n",
    "    model.add(MaxPool1D())\n",
    "    model.add(Conv1D(filter_length, 8, activation='relu'))\n",
    "    model.add(GlobalMaxPool1D())   \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc \n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy', 'top_k_categorical_accuracy', top1_acc, top5_acc, auc])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 119171 samples, validate on 14896 samples\n",
      "Epoch 1/10\n",
      "119171/119171 [==============================] - 802s 7ms/step - loss: 0.0296 - acc: 0.9941 - top_k_categorical_accuracy: 0.3459 - top1_acc: 0.1429 - top5_acc: 0.3459 - auc: 0.7587 - val_loss: 0.0247 - val_acc: 0.9946 - val_top_k_categorical_accuracy: 0.4823 - val_top1_acc: 0.2758 - val_top5_acc: 0.4823 - val_auc: 0.7998\n",
      "Epoch 2/10\n",
      "119171/119171 [==============================] - 797s 7ms/step - loss: 0.0222 - acc: 0.9949 - top_k_categorical_accuracy: 0.5708 - top1_acc: 0.3376 - top5_acc: 0.5708 - auc: 0.8270 - val_loss: 0.0209 - val_acc: 0.9950 - val_top_k_categorical_accuracy: 0.5987 - val_top1_acc: 0.3570 - val_top5_acc: 0.5987 - val_auc: 0.8466\n",
      "Epoch 3/10\n",
      "119171/119171 [==============================] - 798s 7ms/step - loss: 0.0197 - acc: 0.9952 - top_k_categorical_accuracy: 0.6443 - top1_acc: 0.3926 - top5_acc: 0.6443 - auc: 0.8600 - val_loss: 0.0201 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6251 - val_top1_acc: 0.3802 - val_top5_acc: 0.6251 - val_auc: 0.8701\n",
      "Epoch 4/10\n",
      "119171/119171 [==============================] - 797s 7ms/step - loss: 0.0184 - acc: 0.9954 - top_k_categorical_accuracy: 0.6784 - top1_acc: 0.4163 - top5_acc: 0.6784 - auc: 0.8780 - val_loss: 0.0196 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6378 - val_top1_acc: 0.3858 - val_top5_acc: 0.6378 - val_auc: 0.8842\n",
      "Epoch 5/10\n",
      "119171/119171 [==============================] - 797s 7ms/step - loss: 0.0176 - acc: 0.9956 - top_k_categorical_accuracy: 0.6992 - top1_acc: 0.4313 - top5_acc: 0.6992 - auc: 0.8894 - val_loss: 0.0197 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6422 - val_top1_acc: 0.3883 - val_top5_acc: 0.6422 - val_auc: 0.8936\n",
      "Epoch 6/10\n",
      "119171/119171 [==============================] - 797s 7ms/step - loss: 0.0171 - acc: 0.9956 - top_k_categorical_accuracy: 0.7130 - top1_acc: 0.4437 - top5_acc: 0.7130 - auc: 0.8974 - val_loss: 0.0199 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6429 - val_top1_acc: 0.3857 - val_top5_acc: 0.6429 - val_auc: 0.9004\n",
      "Epoch 7/10\n",
      "119171/119171 [==============================] - 798s 7ms/step - loss: 0.0167 - acc: 0.9957 - top_k_categorical_accuracy: 0.7233 - top1_acc: 0.4504 - top5_acc: 0.7233 - auc: 0.9032 - val_loss: 0.0199 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6427 - val_top1_acc: 0.3863 - val_top5_acc: 0.6427 - val_auc: 0.9056\n",
      "Epoch 8/10\n",
      "119171/119171 [==============================] - 799s 7ms/step - loss: 0.0164 - acc: 0.9958 - top_k_categorical_accuracy: 0.7319 - top1_acc: 0.4576 - top5_acc: 0.7319 - auc: 0.9078 - val_loss: 0.0198 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6456 - val_top1_acc: 0.3880 - val_top5_acc: 0.6456 - val_auc: 0.9097\n",
      "Epoch 9/10\n",
      "119171/119171 [==============================] - 799s 7ms/step - loss: 0.0161 - acc: 0.9958 - top_k_categorical_accuracy: 0.7373 - top1_acc: 0.4621 - top5_acc: 0.7373 - auc: 0.9115 - val_loss: 0.0201 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6456 - val_top1_acc: 0.3947 - val_top5_acc: 0.6456 - val_auc: 0.9130\n",
      "Epoch 10/10\n",
      "119171/119171 [==============================] - 799s 7ms/step - loss: 0.0160 - acc: 0.9958 - top_k_categorical_accuracy: 0.7409 - top1_acc: 0.4662 - top5_acc: 0.7409 - auc: 0.9144 - val_loss: 0.0199 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6461 - val_top1_acc: 0.3902 - val_top5_acc: 0.6461 - val_auc: 0.9157\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x_train, y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=16,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/deep_model_word_embedding.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model/deep_model_word_embedding.h5\", \n",
    "                                custom_objects={'top1_acc':top1_acc, 'top5_acc':top5_acc, 'auc':auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14897/14897 [==============================] - 11s 715us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.019864329154100354\n",
      "Test acc: 0.9953191429366599\n",
      "Test top_k_categorical_accuracy: 0.6477143049176094\n",
      "Test top1_acc: 0.39014566692680513\n",
      "Test top5_acc: 0.6477143049176094\n",
      "Test auc: 0.9089150693926018\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(model.metrics_names)):\n",
    "    print(\"Test {}: {}\".format(model.metrics_names[i],score[i]) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
