{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Conv1D, Input, Concatenate, BatchNormalization, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data\n",
    "train_csv = \"assets/train.csv\"\n",
    "df = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 3 1 0 2 6 2 2 3 6 6 0 6 6 2 5 5 4 3 3 4 0 0 2 4 6 4 2 1 6 3 6 3 1 3 2\n",
      " 4 1 1 3 5 6 3 6 0 0 0 6 5 0 6 5 6 0 2 1 6 6 6 1 5 2 3 6 6 4 0 4 4 1 4 1 2\n",
      " 2 6 4 0 6 3 4 5 6 0 6 1 2 3 1 1 3 4 5 0 3 6 3 0 3 1 5 5 6 6 2 2 2 4 3 0 0\n",
      " 0 3 3 4 4 4 2 2 4 3 1 4 3 2 5 1 4 1 5 6 4 2 6 3 0 0 2 3 6 2 3 3 3 3 0 3 2\n",
      " 4 1 0 2 6 3 0 0 4 1 2 6 3 4 0 0 6 4 1 6 5 4 5 0 0 0 1 5 4 0 3 3 1 1 2 2 3\n",
      " 2 0 0 3 6 4 5 1 5 4 6 2 0 4 5 1 1 0 6 2 1 3 6 3 6 6 1 0 2 4 2 4 3 0 6 1 3\n",
      " 2 5 6 5 0 0 3 3 1 6 2 5 2 4 1 6 6 4 5 6 5 1 2 0 0 5 5 0 0 4 4 1 4 3 1 1 0\n",
      " 4 2 0 3 5 6 3 2 3 6 1 2 0 5 2 3 1 4 3 3 1 0 3 6 6 2 3 0 4 4 5 1 4 6 1 1 6\n",
      " 3 4 3 5 4 2 4 2 3 3 2 5 1 6 1 2 3 4 5 4 5 5 4 0 1 5 4 4 4 1 0 4 6 3 4 2 1\n",
      " 3 0 5 4 2 4 6 1 1 3 1 4 1 1 1 5 5 2 0 2 5 5 0 4 6 3 4 3 4 6 5 6 1 6 4 3 2\n",
      " 2 3 1 2 4 1 1 0 6 3 5 5 6 6 4 0 0 2 6 3 0 6 5 6 3 6 4 6 6 5 2 1 6 2 2 5 1\n",
      " 1 3 0 5 2 0 1 1 6 6 2 5 2 3 0 1 0 3 2 2 2 5 2 5 1 4 2 5 2 0 5 6 6 0 0 2 3\n",
      " 0 4 0 2 0 3 2 6 0 0 4 1 2 5 3 3 5 2 1 1 1 5 4 4 5 6 0 5 6 1 1 1 5 0 3 1 3\n",
      " 6 3 5 3 5 2 3 4 4 0 4 5 6 3 1 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "## Labels\n",
    "## labels = np.array(df.values[:,0].tolist())\n",
    "labels = np.array([random.choice([0, 1, 2, 3, 4, 5, 6]) for x in range(df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vob: 334\n",
      "Len: 537\n"
     ]
    }
   ],
   "source": [
    "lines = df.values[:,2].tolist()\n",
    "raw_text = \"\".join(lines)\n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "mapping = dict((c, i + 1) for i, c in enumerate(chars))\n",
    "\n",
    "sequences = []\n",
    "for line in lines:\n",
    "    encoded_seq = [mapping.get(char) for char in line]\n",
    "    sequences.append(encoded_seq)\n",
    "\n",
    "vocab_size = len(mapping) + 1\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Vob: %d\" % vocab_size)\n",
    "print(\"Len: %d\" % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_82 (InputLayer)           (None, 537)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_112 (Embedding)       (None, 537, 16)      5344        input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_308 (Conv1D)             (None, 537, 128)     4224        embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_310 (Conv1D)             (None, 537, 192)     9408        embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_312 (Conv1D)             (None, 537, 256)     16640       embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_314 (Conv1D)             (None, 537, 512)     41472       embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 537, 128)     512         conv1d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 537, 192)     768         conv1d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 537, 256)     1024        conv1d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 537, 512)     2048        conv1d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_309 (Conv1D)             (None, 537, 128)     32896       batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_311 (Conv1D)             (None, 537, 192)     110784      batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_313 (Conv1D)             (None, 537, 256)     262400      batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_315 (Conv1D)             (None, 537, 512)     1311232     batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_114 (MaxPooling1D (None, 268, 128)     0           conv1d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_115 (MaxPooling1D (None, 268, 192)     0           conv1d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_116 (MaxPooling1D (None, 268, 256)     0           conv1d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_117 (MaxPooling1D (None, 268, 512)     0           conv1d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 268, 1088)    0           max_pooling1d_114[0][0]          \n",
      "                                                                 max_pooling1d_115[0][0]          \n",
      "                                                                 max_pooling1d_116[0][0]          \n",
      "                                                                 max_pooling1d_117[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_83 (Flatten)            (None, 291584)       0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 291584)       1166336     flatten_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 7)            2041095     batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7)            28          dense_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 7)            56          batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7)            28          dense_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 6)            48          batch_normalization_132[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 5,006,343\n",
      "Trainable params: 4,415,627\n",
      "Non-trainable params: 590,716\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(max_length, ))\n",
    "\n",
    "embedding = Embedding(vocab_size, 16, input_length=max_length, trainable=False)(inputs)\n",
    "convs = []\n",
    "for n, fsz in [(128, 2), (192, 3), (256, 4), (512, 5)]:\n",
    "    model = Conv1D(n, fsz, activation='relu', padding='same')(embedding)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Conv1D(n, fsz, activation='relu', padding='same')(model)\n",
    "    model = MaxPooling1D()(model)\n",
    "    convs.append(model)\n",
    "\n",
    "model = Concatenate(axis=-1)(convs)\n",
    "model = Flatten()(model)\n",
    "\n",
    "model = BatchNormalization()(model)\n",
    "model = Dense(7, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Dense(7, activation='relu')(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Dense(6, activation='sigmoid')(model)\n",
    "model = Model(inputs, model)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_142 to have shape (6,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-2e0b14648102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/text-classification/env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/text-classification/env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/text-classification/env/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_142 to have shape (6,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(padded_sequences, labels, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
