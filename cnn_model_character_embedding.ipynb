{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import ast\n",
    "import keras\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D,MaxPool1D,GlobalAveragePooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.set_session(session)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = lambda x: ast.literal_eval(x)\n",
    "conv = {'Tags': generic}\n",
    "df = pd.read_csv('data/data_final.csv', converters=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(frac=0.2, random_state=2020)\n",
    "x1 = sample['Body']\n",
    "y1 = sample['Tags']\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_table = sorted(list(set(''.join(df['Body'].values))))\n",
    "vocab_size = len(char_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "for enum, code in enumerate(x2):\n",
    "    try:\n",
    "        code_char =[]\n",
    "        for char in code[:max_length]:\n",
    "            if char in char_table:\n",
    "                code_char.append(char_table.index(char))\n",
    "        code_char_index = code_char + ([0] * (max_length - len(code)))\n",
    "        xs.append(np.array(code_char_index))\n",
    "    except:\n",
    "        print(enum, code)\n",
    "x = np.array(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit_transform(y1)\n",
    "\n",
    "# saving\n",
    "with open('binarizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(multilabel_binarizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('binarizer.pickle', 'rb') as handle:\n",
    "    multilabel_binarizer = pickle.load(handle)\n",
    "\n",
    "y = multilabel_binarizer.transform(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148964, 342)\n",
      "(148964, 200)\n",
      "4435\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(x.shape)\n",
    "print(vocab_size)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119171, 200)\n",
      "(14896, 200)\n",
      "(14897, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          443500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 186, 500)          750500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 342)               137142    \n",
      "=================================================================\n",
      "Total params: 1,531,542\n",
      "Trainable params: 1,531,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Basic CNN model\n",
    "filter_length = 500\n",
    "\n",
    "output_dims = [100]\n",
    "for output_dim in output_dims:\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, output_dim, input_length=x_train.shape[1]))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filter_length, 15, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPool1D())   \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc \n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy', 'top_k_categorical_accuracy', top1_acc, top5_acc, auc])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119171 samples, validate on 14896 samples\n",
      "Epoch 1/10\n",
      "119171/119171 [==============================] - 123s 1ms/step - loss: 0.0240 - acc: 0.9947 - top_k_categorical_accuracy: 0.5573 - top1_acc: 0.3126 - top5_acc: 0.5573 - auc: 0.8169 - val_loss: 0.0191 - val_acc: 0.9953 - val_top_k_categorical_accuracy: 0.6662 - val_top1_acc: 0.3990 - val_top5_acc: 0.6662 - val_auc: 0.8741\n",
      "Epoch 2/10\n",
      "119171/119171 [==============================] - 127s 1ms/step - loss: 0.0186 - acc: 0.9954 - top_k_categorical_accuracy: 0.6877 - top1_acc: 0.4054 - top5_acc: 0.6877 - auc: 0.8898 - val_loss: 0.0179 - val_acc: 0.9954 - val_top_k_categorical_accuracy: 0.6962 - val_top1_acc: 0.4125 - val_top5_acc: 0.6962 - val_auc: 0.8993\n",
      "Epoch 3/10\n",
      "119171/119171 [==============================] - 123s 1ms/step - loss: 0.0174 - acc: 0.9955 - top_k_categorical_accuracy: 0.7145 - top1_acc: 0.4245 - top5_acc: 0.7145 - auc: 0.9060 - val_loss: 0.0175 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7111 - val_top1_acc: 0.4314 - val_top5_acc: 0.7111 - val_auc: 0.9105\n",
      "Epoch 4/10\n",
      "119171/119171 [==============================] - 124s 1ms/step - loss: 0.0167 - acc: 0.9956 - top_k_categorical_accuracy: 0.7322 - top1_acc: 0.4345 - top5_acc: 0.7322 - auc: 0.9144 - val_loss: 0.0174 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7149 - val_top1_acc: 0.4277 - val_top5_acc: 0.7149 - val_auc: 0.9173\n",
      "Epoch 5/10\n",
      "119171/119171 [==============================] - 122s 1ms/step - loss: 0.0163 - acc: 0.9957 - top_k_categorical_accuracy: 0.7421 - top1_acc: 0.4422 - top5_acc: 0.7421 - auc: 0.9200 - val_loss: 0.0174 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7185 - val_top1_acc: 0.4297 - val_top5_acc: 0.7185 - val_auc: 0.9220\n",
      "Epoch 6/10\n",
      "119171/119171 [==============================] - 124s 1ms/step - loss: 0.0160 - acc: 0.9957 - top_k_categorical_accuracy: 0.7516 - top1_acc: 0.4462 - top5_acc: 0.7516 - auc: 0.9240 - val_loss: 0.0173 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7183 - val_top1_acc: 0.4314 - val_top5_acc: 0.7183 - val_auc: 0.9255\n",
      "Epoch 7/10\n",
      "119171/119171 [==============================] - 123s 1ms/step - loss: 0.0157 - acc: 0.9957 - top_k_categorical_accuracy: 0.7583 - top1_acc: 0.4525 - top5_acc: 0.7583 - auc: 0.9271 - val_loss: 0.0174 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7252 - val_top1_acc: 0.4396 - val_top5_acc: 0.7252 - val_auc: 0.9282\n",
      "Epoch 8/10\n",
      "119171/119171 [==============================] - 124s 1ms/step - loss: 0.0155 - acc: 0.9958 - top_k_categorical_accuracy: 0.7633 - top1_acc: 0.4542 - top5_acc: 0.7633 - auc: 0.9295 - val_loss: 0.0174 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7215 - val_top1_acc: 0.4320 - val_top5_acc: 0.7215 - val_auc: 0.9304\n",
      "Epoch 9/10\n",
      "119171/119171 [==============================] - 122s 1ms/step - loss: 0.0153 - acc: 0.9958 - top_k_categorical_accuracy: 0.7664 - top1_acc: 0.4559 - top5_acc: 0.7664 - auc: 0.9315 - val_loss: 0.0176 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7175 - val_top1_acc: 0.4318 - val_top5_acc: 0.7175 - val_auc: 0.9323\n",
      "Epoch 10/10\n",
      "119171/119171 [==============================] - 131s 1ms/step - loss: 0.0152 - acc: 0.9958 - top_k_categorical_accuracy: 0.7696 - top1_acc: 0.4606 - top5_acc: 0.7696 - auc: 0.9331 - val_loss: 0.0177 - val_acc: 0.9956 - val_top_k_categorical_accuracy: 0.7217 - val_top1_acc: 0.4274 - val_top5_acc: 0.7217 - val_auc: 0.9337\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=16,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/basic_model_char_embedding.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model/basic_model_char_embedding.h5\", \n",
    "                                custom_objects={'top1_acc':top1_acc, 'top5_acc':top5_acc, 'auc':auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14897/14897 [==============================] - 5s 315us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.017663229754882433\n",
      "Test acc: 0.9956090466771469\n",
      "Test top_k_categorical_accuracy: 0.7256494596507507\n",
      "Test top1_acc: 0.4310263811565689\n",
      "Test top5_acc: 0.7256494596507507\n",
      "Test auc: 0.9213675592316471\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(model.metrics_names)):\n",
    "    print(\"Test {}: {}\".format(model.metrics_names[i],score[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 100)          443500    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 186, 500)          750500    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 179, 500)          2000500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 89, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 82, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 41, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 34, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 400)               200400    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 342)               137142    \n",
      "=================================================================\n",
      "Total params: 7,533,042\n",
      "Trainable params: 7,533,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Deep CNN Model\n",
    "filter_length = 500\n",
    "output_dims = [100]\n",
    "for output_dim in output_dims:\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, output_dim, input_length=x_train.shape[1]))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filter_length, 15, padding='valid', activation='relu', strides=1))\n",
    "    model.add(Conv1D(filter_length, 8,activation='relu'))\n",
    "    model.add(MaxPool1D())\n",
    "    model.add(Conv1D(filter_length, 8,activation='relu'))\n",
    "    model.add(MaxPool1D())\n",
    "    model.add(Conv1D(filter_length, 8, activation='relu'))\n",
    "    model.add(GlobalMaxPool1D())   \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "    \n",
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc \n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy', 'top_k_categorical_accuracy', top1_acc, top5_acc, auc])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119171 samples, validate on 14896 samples\n",
      "Epoch 1/10\n",
      "119171/119171 [==============================] - 393s 3ms/step - loss: 0.0303 - acc: 0.9941 - top_k_categorical_accuracy: 0.3226 - top1_acc: 0.1164 - top5_acc: 0.3226 - auc: 0.7556 - val_loss: 0.0251 - val_acc: 0.9946 - val_top_k_categorical_accuracy: 0.4778 - val_top1_acc: 0.2575 - val_top5_acc: 0.4778 - val_auc: 0.7880\n",
      "Epoch 2/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0232 - acc: 0.9948 - top_k_categorical_accuracy: 0.5443 - top1_acc: 0.3039 - top5_acc: 0.5443 - auc: 0.8144 - val_loss: 0.0217 - val_acc: 0.9950 - val_top_k_categorical_accuracy: 0.5843 - val_top1_acc: 0.3377 - val_top5_acc: 0.5843 - val_auc: 0.8341\n",
      "Epoch 3/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0215 - acc: 0.9951 - top_k_categorical_accuracy: 0.5956 - top1_acc: 0.3452 - top5_acc: 0.5956 - auc: 0.8461 - val_loss: 0.0213 - val_acc: 0.9951 - val_top_k_categorical_accuracy: 0.5932 - val_top1_acc: 0.3464 - val_top5_acc: 0.5932 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0210 - acc: 0.9951 - top_k_categorical_accuracy: 0.6098 - top1_acc: 0.3561 - top5_acc: 0.6098 - auc: 0.8614 - val_loss: 0.0210 - val_acc: 0.9951 - val_top_k_categorical_accuracy: 0.6059 - val_top1_acc: 0.3481 - val_top5_acc: 0.6059 - val_auc: 0.8664\n",
      "Epoch 5/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0207 - acc: 0.9952 - top_k_categorical_accuracy: 0.6180 - top1_acc: 0.3616 - top5_acc: 0.6180 - auc: 0.8703 - val_loss: 0.0209 - val_acc: 0.9951 - val_top_k_categorical_accuracy: 0.6165 - val_top1_acc: 0.3548 - val_top5_acc: 0.6165 - val_auc: 0.8735\n",
      "Epoch 6/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0205 - acc: 0.9952 - top_k_categorical_accuracy: 0.6227 - top1_acc: 0.3668 - top5_acc: 0.6227 - auc: 0.8761 - val_loss: 0.0206 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6202 - val_top1_acc: 0.3657 - val_top5_acc: 0.6202 - val_auc: 0.8784\n",
      "Epoch 7/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0205 - acc: 0.9952 - top_k_categorical_accuracy: 0.6258 - top1_acc: 0.3707 - top5_acc: 0.6258 - auc: 0.8804 - val_loss: 0.0206 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6183 - val_top1_acc: 0.3653 - val_top5_acc: 0.6183 - val_auc: 0.8821\n",
      "Epoch 8/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0203 - acc: 0.9952 - top_k_categorical_accuracy: 0.6287 - top1_acc: 0.3713 - top5_acc: 0.6287 - auc: 0.8837 - val_loss: 0.0206 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6196 - val_top1_acc: 0.3671 - val_top5_acc: 0.6196 - val_auc: 0.8849\n",
      "Epoch 9/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0202 - acc: 0.9952 - top_k_categorical_accuracy: 0.6322 - top1_acc: 0.3746 - top5_acc: 0.6322 - auc: 0.8862 - val_loss: 0.0206 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6258 - val_top1_acc: 0.3696 - val_top5_acc: 0.6258 - val_auc: 0.8872\n",
      "Epoch 10/10\n",
      "119171/119171 [==============================] - 396s 3ms/step - loss: 0.0202 - acc: 0.9952 - top_k_categorical_accuracy: 0.6340 - top1_acc: 0.3752 - top5_acc: 0.6340 - auc: 0.8883 - val_loss: 0.0205 - val_acc: 0.9952 - val_top_k_categorical_accuracy: 0.6229 - val_top1_acc: 0.3684 - val_top5_acc: 0.6229 - val_auc: 0.8891\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x_train, y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=16,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/deep_model_char_embedding.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "top5_acc = functools.partial(tf.keras.metrics.top_k_categorical_accuracy, k = 5)\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "top5_acc.__name__ = 'top5_acc'\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model/deep_model_char_embedding.h5\", \n",
    "                                custom_objects={'top1_acc':top1_acc, 'top5_acc':top5_acc, 'auc':auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14897/14897 [==============================] - 11s 726us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.020423251952214026\n",
      "Test acc: 0.9952376871658922\n",
      "Test top_k_categorical_accuracy: 0.6231455998172006\n",
      "Test top1_acc: 0.3645700476706056\n",
      "Test top5_acc: 0.6231455998172006\n",
      "Test auc: 0.9035350808787124\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(model.metrics_names)):\n",
    "    print(\"Test {}: {}\".format(model.metrics_names[i],score[i]) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
